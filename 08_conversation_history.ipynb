{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7fbc562b4d00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fbc562b61a0>, model_name='gemma2-9b-it')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Prodip, it's nice to meet you!\\n\\nI'm glad to hear you're working with AI. It's a fascinating field with so many possibilities.\\n\\nWhat kind of work are you doing with AI? \\n\\nI'm always eager to learn more about how people are using AI to make a difference.\\n\", response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 22, 'total_tokens': 94, 'completion_time': 0.130909091, 'prompt_time': 0.002274385, 'queue_time': 0.231737944, 'total_time': 0.133183476}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d1e31e50-910c-4beb-8510-ac0583dc793b-0', usage_metadata={'input_tokens': 22, 'output_tokens': 72, 'total_tokens': 94})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Hi,my name is prodip and I am working with AI\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Prodip, and you're working with AI!  \\n\\nIs there anything else you'd like to tell me about your work? Perhaps what kind of AI you're using or what problems you're trying to solve? üòä  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 112, 'total_tokens': 171, 'completion_time': 0.107272727, 'prompt_time': 0.005962558, 'queue_time': 0.23467506, 'total_time': 0.113235285}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-05c0a1ec-61c9-4260-930b-8a7bbe9619f2-0', usage_metadata={'input_tokens': 112, 'output_tokens': 59, 'total_tokens': 171})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi,my name is prodip and I am working with AI\"),\n",
    "        AIMessage(content=\"Hi Prodip, it's nice to meet you!\\n\\nI'm glad to hear you're working with AI. It's a fascinating field with so many possibilities.\\n\\nWhat kind of work are you doing with AI? \\n\\nI'm always eager to learn more about how people are using AI to make a difference.\\n\"),\n",
    "        HumanMessage(content=\"Hey whats my name and what do i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    \"\"\"\n",
    "    Get the session history for a given session ID.\n",
    "    \"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi,my name is prodip and I am working with AI\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Prodip!  \\n\\nIt's great to meet you. What kind of work are you doing with AI? Are you developing new models, using AI for a specific task, or something else entirely? \\n\\nI'm eager to hear more about your experience! üòä  \\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Prodip.  \\n\\nI remember from our previous conversation! üòä  \\n\\n\\n\\n\\n', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 174, 'total_tokens': 195, 'completion_time': 0.038181818, 'prompt_time': 0.007420874, 'queue_time': 0.23098263500000002, 'total_time': 0.045602692}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3989aa59-4c52-4b00-b27a-10ee76565903-0', usage_metadata={'input_tokens': 174, 'output_tokens': 21, 'total_tokens': 195})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to use it!\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the session id -> config\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Dev, it's nice to meet you! üòä\\n\\nIs there anything I can help you with today?\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is Dev \")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Dev. I remember! üòä  \\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Prodip, it's nice to meet you!\\n\\nI'm ready to answer your questions to the best of my ability. Just ask away! üòä  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 30, 'total_tokens': 68, 'completion_time': 0.069090909, 'prompt_time': 0.002823894, 'queue_time': 0.257635795, 'total_time': 0.071914803}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f298903c-7af8-43bc-ab0d-d454961775f3-0', usage_metadata={'input_tokens': 30, 'output_tokens': 38, 'total_tokens': 68})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":[HumanMessage(content=\"my name is Prodip\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Prodip, it's nice to meet you! I'm happy to help with any questions you have.  \\n\\nWhat can I do for you today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi,My name is Prodip\")],\n",
    "    config=config3\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Answer all the question to the best of your ability {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶¶‡ßÄ‡¶™! üòä \\n\\n‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶õ‡¶ø‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡ßã‡¶® ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ü‡¶õ‡ßá?  \\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Prodip\")],\n",
    "              \"language\":\"bengali\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞, ‡¶™‡ßç‡¶∞‡¶¶‡ßÄ‡¶™! \\n\\n‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø‡¶ï‡¶æ‡¶∞‡ßÄ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶õ‡¶ø‡•§  ‡¶ï‡ßã‡¶®‡¶ì ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ü‡¶õ‡ßá? üòä \\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config4={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi,I am Prodip\")],\n",
    "     'language':'bengali'},\n",
    "    config=config4\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶™‡ßç‡¶∞‡¶¶‡ßÄ‡¶™‡•§ üòä \\n\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"What's my name ?\")],\n",
    "     'language':'bengali'},\n",
    "    config=config4\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hackthebox/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hackthebox/Downloads/genai/genai/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.'),\n",
       " HumanMessage(content='Hi, my name is Prodip.'),\n",
       " AIMessage(content=\"Hi Prodip, it's nice to meet you!\"),\n",
       " HumanMessage(content=\"What's my name?\"),\n",
       " AIMessage(content='Your name is Prodip.'),\n",
       " HumanMessage(content='What do I do?'),\n",
       " AIMessage(content=\"I'm not sure what you do.\"),\n",
       " HumanMessage(content='I work with AI.'),\n",
       " AIMessage(content=\"That's interesting! What kind of work do you do with AI?\")]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi, my name is Prodip.\"),\n",
    "    AIMessage(content=\"Hi Prodip, it's nice to meet you!\"),\n",
    "    HumanMessage(content=\"What's my name?\"),\n",
    "    AIMessage(content=\"Your name is Prodip.\"),\n",
    "    HumanMessage(content=\"What do I do?\"),\n",
    "    AIMessage(content=\"I'm not sure what you do.\"),\n",
    "    HumanMessage(content=\"I work with AI.\"),\n",
    "    AIMessage(content=\"That's interesting! What kind of work do you do with AI?\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said you work with AI.  \\n\\nIs there something specific you'd like to tell me about your work? I'm curious to learn more! üòä \\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")| trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"What do I do?\")],\n",
    "        \"language\":\"english\"\n",
    "    }\n",
    "    \n",
    "     \n",
    "     )\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config5={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said you work with AI.  \\n\\nWould you like to tell me more about what you do? I'm curious to learn! üòä  \\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"What do I do?\")],\n",
    "        \"language\":\"english\"\n",
    "    },\n",
    "    config=config5\n",
    "\n",
    "    \n",
    "     \n",
    "     )\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
