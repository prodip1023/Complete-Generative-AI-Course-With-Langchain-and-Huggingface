{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7fbb97a9b250> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fbb97ac5270> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is a subset of artificial intelligence focused on creating new content, such as text, images, music, or even entire virtual environments. It uses models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models to generate data that mimics real-world examples.\n",
      "\n",
      "### Key Aspects of Generative AI:\n",
      "\n",
      "1. **Models and Techniques**:\n",
      "   - **GANs**: Consist of two networks, a generator and a discriminator, that work against each other to produce realistic outputs.\n",
      "   - **VAEs**: Use probabilistic methods to generate data similar to the input data.\n",
      "   - **Transformers**: Particularly in natural language processing, models like GPT (Generative Pre-trained Transformer) generate human-like text.\n",
      "\n",
      "2. **Applications**:\n",
      "   - **Text Generation**: Producing articles, stories, or even code.\n",
      "   - **Image Creation**: Generating art, photorealistic images, or modifying existing images.\n",
      "   - **Music and Audio**: Composing music or generating human-like speech.\n",
      "   - **Video**: Creating or editing video content.\n",
      "   - **Virtual Worlds**: Designing game environments or simulations.\n",
      "\n",
      "3. **Challenges**:\n",
      "   - **Quality and Realism**: Ensuring outputs are indistinguishable from human-created content.\n",
      "   - **Ethical Concerns**: Issues like deepfakes, misinformation, and copyright infringement.\n",
      "   - **Bias and Fairness**: Addressing biases present in training data that can affect generated content.\n",
      "\n",
      "4. **Future Directions**:\n",
      "   - **Improved Models**: Developing more efficient and capable models.\n",
      "   - **Ethical Guidelines**: Establishing standards for responsible use.\n",
      "   - **Integration**: Combining with other AI technologies for more advanced applications.\n",
      "\n",
      "Generative AI continues to evolve, with ongoing research addressing its limitations and expanding its capabilities across various industries.\n"
     ]
    }
   ],
   "source": [
    "# Input and get response from LLM\n",
    "result = llm.invoke(\"How is generative AI\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer.Provide me answers based on the question')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer.Provide me answers based on the question\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform associated with LangChain, a framework designed to simplify the development of applications using large language models (LLMs). It offers tools and services to help developers manage, deploy, and optimize LLM-powered applications. Langsmith provides features such as tracing, monitoring, and debugging, which are essential for improving the performance and reliability of applications that leverage LLMs. By using Langsmith, developers can more effectively harness the capabilities of LLMs, ensuring that their applications are both efficient and scalable.' response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 32, 'total_tokens': 136, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'finish_reason': 'stop', 'logprobs': None} id='run-b60117d9-a629-4a06-8d60-0732422ba416-0' usage_metadata={'input_tokens': 32, 'output_tokens': 104, 'total_tokens': 136}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stroutput Parser\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform developed by LangChain, designed to enhance the development and deployment of language model applications. It provides a suite of tools that allow developers to easily trace, visualize, and evaluate the performance of their language models. Langsmith also offers robust features for managing datasets, which can be used to train and fine-tune models. Its capabilities are particularly useful for those working with complex language processing tasks, enabling them to efficiently analyze model outputs and iterate on application development. This platform simplifies the integration of language models into various applications by offering extensive support for testing and optimizing model performance.\n"
     ]
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
